
# ----------------------------------------------------------------------------
# Imports 
# ----------------------------------------------------------------------------
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score



# ----------------------------------------------------------------------------
# Globals
# ----------------------------------------------------------------------------

ALL_MODELS = ['KNN' , 'RF' , 'SVM' , 'LR']



# ----------------------------------------------------------------------------
# Modules 
# ----------------------------------------------------------------------------


class Evaluator():

    """
    Dataset evauation using train-test split of dataset given spesific ratio
    """
    def test_train_dataset(self, dataset_file_path, model, features_count, split_test_size=0.3):
        dataset = np.genfromtxt(dataset_file_path, delimiter=',')

        data = dataset[:,0:features_count]
        labels = dataset[:, features_count]

        x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=split_test_size) 

        if model == 'KNN':
            classifier = KNeighborsClassifier(n_neighbors=55, p=2,metric='euclidean')
        elif model == 'RF':
            classifier = RandomForestClassifier(n_jobs=2)
        elif model == 'SVM':
            classifier = LinearSVC(max_iter=10000)
        elif model == 'LR':
            classifier = LogisticRegression()

        print(f"Evaluation dataset using {model} model")


        classifier.fit(x_train, y_train)
        y_pred = classifier.predict(x_test)

        print(f"F1 = {f1_score(y_test, y_pred)}")
        print(f"Accuracy Score = {accuracy_score(y_test, y_pred)}")


    """
    Dataset evauation using K-Fold cross validation (K=5) given a spesific model and dataset to use
    """
    def evaluate_dataset(self, dataset_file_path, model, features_count):
        dataset = np.genfromtxt(dataset_file_path, delimiter=',')

        data = dataset[:,0:features_count]
        labels = dataset[:, features_count]

        if model == 'KNN':
            classifier = KNeighborsClassifier(n_neighbors=55, p=2,metric='euclidean')
        elif model == 'RF':
            classifier = RandomForestClassifier(n_jobs=2)  #random_state=0)
        elif model == 'SVM':
            classifier = LinearSVC()
        elif model == 'LR':
            classifier = LogisticRegression()

        print(f"Evaluation dataset using {model} model")

        scores = cross_val_score(classifier, data, labels, cv=5)
        print(f"Accuracy Score={scores.mean()}")

        f1_scores = cross_val_score(classifier, data, labels, scoring='f1_macro', cv=5)
        print(f"F1 Score= {f1_scores.mean()} \n")



    """
    Run K-Fold cross validation on all supported model of given dataset 
    """
    def evaluate_dataset_all_classifiers(self, dataset_file_path, features_count):
        for model in ALL_MODELS:
            self.evaluate_dataset(dataset_file_path, model, features_count)
