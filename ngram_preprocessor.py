# ----------------------------------------------------------------------------
# Imports 
# ----------------------------------------------------------------------------

import numpy as np
from nltk import ngrams
import torch
import glob
import os
import logging

import pefile
import capstone

from utils import *


# ----------------------------------------------------------------------------
# Globals and constants
# ----------------------------------------------------------------------------

REAL_CODE_SECTION_SIZE_THRESHOLD = 100


# ----------------------------------------------------------------------------
# Classes 
# ----------------------------------------------------------------------------


class NgramPreprocessor():

	def __init__(self):
		pass

	def export_to_csv(self, outfile_path, sequences_mat, sequence_freqs):
		# concatanete frequencies array to be the last column of the sequenes matrix
		sequence_freqs = sequence_freqs.reshape(len(sequence_freqs), 1)
		result_matrix = np.concatenate((sequences_mat, sequence_freqs), axis=1)

		CSV_FILE_HEADER = 'OPCODE1, OPCODE2, FREQUENCY'
		np.savetxt(outfile_path, result_matrix , fmt='%s', delimiter=',', header=CSV_FILE_HEADER)


	#@timeit
	def calc_ngram_pure_python(self,twogram_array):
		hist = [((hex(seq[0]),hex(seq[1])), twogram.count(seq)) for seq in unique_sequences[:HISTOGRAM_SIZE]]
		return hist

	#@timeit
	def calc_ngram_numpy(self,twogram_array):
		unique_sequences, sequence_freqs = np.unique(twogram_array, axis=0, return_counts=True)
		return (unique_sequences, sequence_freqs)


	#@timeit
	def calc_ngram_gpu_accelerated(self, twogram_array):
		device_gpu = torch.device("cuda:0")

		# convert array to tensor object and copy to GPU memory 
		twogram_tensor = torch.from_numpy(twogram_array)
		twogram_tensor = twogram_tensor.to(device_gpu)

		unique_sequences, sequence_freqs = torch.unique(twogram_tensor,  return_counts=True, dim=0)

		# Move tensor back to CPU memory, as numpy arrays
		unique_sequences = unique_sequences.detach().cpu().numpy()
		sequence_freqs = sequence_freqs.detach().cpu().numpy()

		return (unique_sequences, sequence_freqs)


	def cleanup_gpu_reasources(self):
		torch.cuda.empty_cache()


	def extract_opcodes_list(self, pe):
		opcodes_list = []

		# Find text (code) section and extract it
		for section in pe.sections:
			if 'text' in str(section.Name):
				code_section = section
				break

		raw_code = code_section.get_data()

		# initialize disassembler to of the correct architecture 
		if pe.FILE_HEADER.Machine == 0x014c:
			pe_architecutre = capstone.CS_MODE_32

		if pe.FILE_HEADER.Machine == 0x8664:
			pe_architecutre = capstone.CS_MODE_64

		disassembler = capstone.Cs(capstone.CS_ARCH_X86, pe_architecutre)
		code_section_size = code_section.SizeOfRawData

		"""
		Go over all text section where binary code should be
		Disassemble every chunck and add the opcodes found to the opcodes list
		"""
		cursor = 0 
		while cursor < code_section_size:

			opcodes = []
			code = raw_code[cursor:]
			disassembly_generator = disassembler.disasm(code, 0)

			for instruction in disassembly_generator:
				opcodes.append(instruction.mnemonic)
				cursor += instruction.size

			cursor += 1

			if (len(opcodes) > REAL_CODE_SECTION_SIZE_THRESHOLD):
				opcodes_list += opcodes

		return opcodes_list


	@timeit
	def extract_ngram_of_file(self, in_file_path, out_file_path):

		try:
			# load the target PE file
			pe = pefile.PE(in_file_path)

			opcodes_list = self.extract_opcodes_list(pe)
			print(f"Opcodes Count: {len(opcodes_list)}")

			#print (opcodes_list[:50])
			#print("\n")
			#print (opcodes_list[-50:])

		    # Now extrat twogram vector out of the binary file's opcodes list
			twogram_iter = ngrams(opcodes_list, 2)
			twogram_array = np.array(list(twogram_iter))
			unique_sequences, sequence_freqs = self.calc_ngram_numpy(twogram_array)

			self.export_to_csv(out_file_path, unique_sequences, sequence_freqs)

		except Exception as ex:
			msg = f'====================> ERROR EXTRACTING NGRAM of: {in_file_path} \t|' + str(ex)
			logging.getLogger().error(msg)



	def process_all_files_in_dir(self, in_directory_path, out_directory_path):

		for filepath in glob.iglob(f'{in_directory_path}/*.exe'):
			basename = os.path.basename(filepath)
			
			print('----------------------------------------------------------------------------')
			print('Processing:   ' + filepath)
			self.extract_ngram_of_file(filepath, f'{out_directory_path}/{basename}-ngram.csv')
			print('----------------------------------------------------------------------------')



	def __del__(self):
		self.cleanup_gpu_reasources()