# ----------------------------------------------------------------------------
# Imports 
# ----------------------------------------------------------------------------

import numpy as np
from nltk import ngrams
import torch
import glob
import os

import pefile
import capstone

from utils import *


# ----------------------------------------------------------------------------
# Globals
# ----------------------------------------------------------------------------




# ----------------------------------------------------------------------------
# Classes 
# ----------------------------------------------------------------------------


class NgramPreprocessor():

	def __init__(self):
		pass

	def export_to_csv(self, outfile_path, sequences_mat, sequence_freqs):
		# concatanete frequencies array to be the last column of the sequenes matrix
		sequence_freqs = sequence_freqs.reshape(len(sequence_freqs), 1)
		result_matrix = np.concatenate((sequences_mat, sequence_freqs), axis=1)

		CSV_FILE_HEADER = 'OPCODE1, OPCODE2, FREQUENCY'
		np.savetxt(outfile_path, result_matrix , fmt='%s', delimiter=',', header=CSV_FILE_HEADER)


	#@timeit
	def calc_ngram_pure_python(self,twogram_array):
		hist = [((hex(seq[0]),hex(seq[1])), twogram.count(seq)) for seq in unique_sequences[:HISTOGRAM_SIZE]]
		return hist

	#@timeit
	def calc_ngram_numpy(self,twogram_array):
		unique_sequences, sequence_freqs = np.unique(twogram_array, axis=0, return_counts=True)
		return (unique_sequences, sequence_freqs)


	#@timeit
	def calc_ngram_gpu_accelerated(self, twogram_array):
		device_gpu = torch.device("cuda:0")

		# convert array to tensor object and copy to GPU memory 
		twogram_tensor = torch.from_numpy(twogram_array)
		twogram_tensor = twogram_tensor.to(device_gpu)

		unique_sequences, sequence_freqs = torch.unique(twogram_tensor,  return_counts=True, dim=0)

		# Move tensor back to CPU memory, as numpy arrays
		unique_sequences = unique_sequences.detach().cpu().numpy()
		sequence_freqs = sequence_freqs.detach().cpu().numpy()

		return (unique_sequences, sequence_freqs)


	def cleanup_reasources(self):
		torch.cuda.empty_cache()


	@timeit
	def extract_ngram_of_file(self, in_file_path, out_file_path):

		# load the target PE file
		pe = pefile.PE(in_file_path)

		# get the address of the program entry point from the program header
		entrypoint = pe.OPTIONAL_HEADER.AddressOfEntryPoint

		# compute memory address where the entry code will be loaded into memory
		entrypoint_address = entrypoint + pe.OPTIONAL_HEADER.ImageBase

		# get the binary code from the PE file object
		binary_code = pe.get_memory_mapped_image()[entrypoint:]
		# initialize disassembler to of the correct architecture 
		if pe.FILE_HEADER.Machine == 0x014c:
			pe_architecutre = capstone.CS_MODE_32

		if pe.FILE_HEADER.Machine == 0x8664:
			pe_architecutre = capstone.CS_MODE_64

		disassembler = capstone.Cs(capstone.CS_ARCH_X86, pe_architecutre)

		# Retrive opcodes list out of the parsed PE file
		opcodes_list = [instruction.mnemonic for instruction in disassembler.disasm(binary_code, entrypoint_address)]

		print(f"Code Section size is --------------> {len(binary_code)}")
		print(f"Opcodes list size is --------------> {len(opcodes_list)}")

	    # Now extrat twogram vector out of the binary file's opcodes list
		twogram_iter = ngrams(opcodes_list, 2)
		twogram_array = np.array(list(twogram_iter)) #dtype=np.uint8)
		unique_sequences, sequence_freqs = self.calc_ngram_numpy(twogram_array)

		self.export_to_csv(out_file_path, unique_sequences, sequence_freqs)



	def process_all_files_in_dir(self, in_directory_path, out_directory_path):

		for filepath in glob.iglob(f'{in_directory_path}/*.exe'):
			basename = os.path.basename(filepath)
			
			print('----------------------------------------------------------------------------')
			print('Processing:   ' + filepath)
			self.extract_ngram_of_file(filepath, f'{out_directory_path}/{basename}-ngram.csv')
			print('----------------------------------------------------------------------------')



	def __del__(self):
		self.cleanup_reasources()