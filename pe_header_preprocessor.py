# ----------------------------------------------------------------------------
# Imports 
# ----------------------------------------------------------------------------

import pefile
import numpy as np
import glob
import logging
import os

from md_exception import *
from preprocessor import Preprocessor
from utils import *
from common import *




# ----------------------------------------------------------------------------
# Constants 
# ----------------------------------------------------------------------------

TEMP_OUTPUT_FILENAME_MOST_USED_API_FUNCTIONS = 'PE_HEADERS_PREPROCESSOR_most_used_api_functions.csv'


# ----------------------------------------------------------------------------
# Classes 
# ----------------------------------------------------------------------------

class PeHeaderPreprocessor(Preprocessor):

    def __init__(self, features_count, benign_files_input_dir, malicious_files_input_dir, most_used_api_functions_file_path=''):
        super().__init__(features_count, benign_files_input_dir, malicious_files_input_dir)
        self.prepare_data(most_used_api_functions_file_path)


    def prepare_data(self, most_used_api_functions_file_path):

        # if most used api functions file is already created than use that one (as cache)
        # Otherwise - process all malware file and create it
        if most_used_api_functions_file_path:
            most_used_api_functions_mat = np.genfromtxt(most_used_api_functions_file_path, skip_header=True, dtype=str, delimiter=',')
        else:
            most_used_api_functions_mat = self.extract_most_common_api_functions_used(self._malicious_files_input_dir, TEMP_OUTPUT_FILENAME_MOST_USED_API_FUNCTIONS)

        # Sort that array from most used functions first. 
        most_used_api_functions_mat = sorted(list(most_used_api_functions_mat), reverse=True, key=lambda pair : int(pair[1]))

        # Extract most used api functions, in count of features count. 
        self._most_used_api_functions = np.array(most_used_api_functions_mat)[0:self._features_count ,0]



    def extract_api_functions_vector(self, filepath):
        try:
            pe = pefile.PE(filepath)

            api_functions_vector = []

            for entry in pe.DIRECTORY_ENTRY_IMPORT:
                dll_entry_functions = [func.name.decode('utf-8') for func in entry.imports if func.name]
                api_functions_vector += (dll_entry_functions)

            #api_functions_vector = np.array(api_functions_vector)
            #np.savetxt('api_functions_vector_example.csv' , api_functions_vector.reshape(1, api_functions_vector.shape[0]) , fmt='%s', delimiter=',')
            #print(api_functions_vector.shape)

            return api_functions_vector

        except Exception as ex:
            logging.getLogger().error(str(ex))
            return []

            

    def extract_most_common_api_functions_used(self, in_directory_path, out_filepath):

        all_functions_dict = {}

        for filepath in glob.iglob(f'{in_directory_path}/*.exe'):

            print('Processing: ' + filepath)
            api_functions_vector = self.extract_api_functions_vector(filepath)

            for function_name in api_functions_vector:

                if not function_name in all_functions_dict:
                    all_functions_dict[function_name] = 1

                else:
                    all_functions_dict[function_name] = all_functions_dict[function_name] + 1


        # Now export that dictionary to csv file
        api_functions_counts_arr = [(func, count) for func, count in all_functions_dict.items()]
        api_functions_counts_arr = np.array(api_functions_counts_arr)

        if out_filepath:
            CSV_FILE_HEADER = 'FUNCTION, COUNT'
            np.savetxt(out_filepath, api_functions_counts_arr , fmt='%s', delimiter=',', header=CSV_FILE_HEADER)

        return api_functions_counts_arr



    def get_feature_vector(self, file_path):

        if not os.path.isfile(file_path):
            raise FeaturesExtractionException("File not exsists!")

        api_functions_vector = self.extract_api_functions_vector(file_path)
        if not api_functions_vector:
            return None

        feature_vector = [1 if func_name in api_functions_vector else 0 for func_name in self._most_used_api_functions]
        return np.array(feature_vector)


    def _create_partial_dataset(self, exe_files_input_dir):
       
        feature_vectors_list = []

        for filepath in glob.iglob(f'{exe_files_input_dir}/*.exe'):

            print('Processing: ' + filepath)
            feature_vector = self.get_feature_vector(filepath)
            if feature_vector is None:
                continue

            feature_vectors_list.append(feature_vector)

        return np.array(feature_vectors_list)
    

    def create_dataset(self, output_dataset_file):

        benign_partial_dataset = self._create_partial_dataset(self._benign_files_input_dir)
        malicious_partial_dataset = self._create_partial_dataset(self._malicious_files_input_dir)

        # push to each matrix 1 coulumn of label 
        benign_dataset = np.column_stack((benign_partial_dataset, np.ones(benign_partial_dataset.shape[0]) * LABEL_BENIGN))
        malicious_dataset = np.column_stack((malicious_partial_dataset, np.ones(malicious_partial_dataset.shape[0]) * LABEL_MALICIOUS))

        final_dataset = np.concatenate((benign_dataset, malicious_dataset))
        np.savetxt(output_dataset_file, final_dataset , fmt='%s', delimiter=',')




    def debug__analyze_file(self, filepath):
        pe = pefile.PE(filepath)
        print(f"[*] Listing imported DLLs of file:   {filepath} ")

        for entry in pe.DIRECTORY_ENTRY_IMPORT:
            print('----------------------------------------------------------------------------')
            print('\t' + entry.dll.decode('utf-8'))
            print('\n')

            for func in entry.imports:
                if func.name:
                    print(func.name.decode('utf-8'))
                


