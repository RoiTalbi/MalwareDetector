# ----------------------------------------------------------------------------
# Imports 
# ----------------------------------------------------------------------------

from pyaxmlparser import APK # external lib

import numpy as np
import glob
import os
import logging

from preprocessor import Preprocessor
from utils import *
from common import *

# ----------------------------------------------------------------------------
# Globals and constants
# ----------------------------------------------------------------------------




# ----------------------------------------------------------------------------
# Classes 
# ----------------------------------------------------------------------------


class APKPreprocessor(Preprocessor):

    def __init__(self, features_count):
    	self._features_count = features_count


    def extract_permissions_list(self, filepath):
        try:
            # Extact APK info using pyaxmlparser lib
            apk_info = APK(filepath)

            permissions_list = apk_info.get_declared_permissions() + apk_info.get_permissions()
            return permissions_list

        except Exception as ex:
            logging.getLogger().error(str(ex))
            return []



    def extract_most_common_permissions_used(self, in_directory_path, out_filepath):
        all_permissions_dict = {}

        for filepath in glob.iglob(f'{in_directory_path}/*'):

        	# Extract persmissions list of each apk file and update the dictionary with each permission count accordingly 

            print('Processing: ' + filepath)
            permissions_list = self.extract_permissions_list(filepath)

            for permission_name in permissions_list:

                if not permission_name in all_permissions_dict:
                    all_permissions_dict[permission_name] = 1

                else:
                    all_permissions_dict[permission_name] = all_permissions_dict[permission_name] + 1


        # Now export that dictionary to csv file
        permissions_frequency_mat = [(perm, count) for perm, count in all_permissions_dict.items()]
        permissions_frequency_mat = np.array(permissions_frequency_mat)

        CSV_FILE_HEADER = 'PERMISSION, COUNT'
        np.savetxt(out_filepath, permissions_frequency_mat , fmt='%s', delimiter=',', header=CSV_FILE_HEADER)



    def _create_partial_dataset(self, most_used_permissions,  apk_files_input_dir):
       
        feature_vectors_list = []

        for filepath in glob.iglob(f'{apk_files_input_dir}/*'):

            print('Processing: ' + filepath)
            permissions_list = self.extract_permissions_list(filepath)
            if not permissions_list:
                continue

            feature_vector = [1 if permission in permissions_list else 0 for permission in most_used_permissions]
            feature_vectors_list.append(feature_vector)

        return np.array(feature_vectors_list)



    def create_dataset(self, most_used_permissions_file, benign_files_input_dir, malicious_files_input_dir, output_dataset_file):

        most_used_permissions_mat = np.genfromtxt(most_used_permissions_file, skip_header=True, dtype=str, delimiter=',')

        # Sort that array from most used functions first. 
        most_used_permissions_mat = sorted(list(most_used_permissions_mat), reverse=True, key=lambda pair : int(pair[1]))

        # Extract most used api functions, in count of features count. 
        most_used_permissions_array = np.array(most_used_permissions_mat)[0:self._features_count ,0]

        benign_partial_dataset = self._create_partial_dataset(most_used_permissions_array, benign_files_input_dir)
        malicious_partial_dataset = self._create_partial_dataset(most_used_permissions_array, malicious_files_input_dir)

        # push to each matrix 1 coulumn of label 
        benign_dataset = np.column_stack((benign_partial_dataset, np.ones(benign_partial_dataset.shape[0]) * LABEL_BENIGN))
        malicious_dataset = np.column_stack((malicious_partial_dataset, np.ones(malicious_partial_dataset.shape[0]) * LABEL_MALICIOUS))

        final_dataset = np.concatenate((benign_dataset, malicious_dataset))
        np.savetxt(output_dataset_file, final_dataset , fmt='%s', delimiter=',')