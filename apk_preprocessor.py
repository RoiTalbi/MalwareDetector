# ----------------------------------------------------------------------------
# Imports 
# ----------------------------------------------------------------------------

from pyaxmlparser import APK # external lib

import numpy as np
import glob
import os
import logging

from md_exception import *
from preprocessor import Preprocessor
from utils import *
from common import *

# ----------------------------------------------------------------------------
# Globals and constants
# ----------------------------------------------------------------------------

TEMP_OUTPUT_FILENAME_MOST_COMMON_PERMISSIONS = 'APK_PREPROCESSOR_most_common_permissions.csv'




# ----------------------------------------------------------------------------
# Classes 
# ----------------------------------------------------------------------------


class APKPreprocessor(Preprocessor):

    def __init__(self, features_count, benign_files_input_dir, malicious_files_input_dir, most_used_permissions_file_path=''):
        super().__init__(features_count, benign_files_input_dir, malicious_files_input_dir)
        self.prepare_data(most_used_permissions_file_path)


    def prepare_data(self, most_used_permissions_file_path):

        # if most used permission file is already created than use that one
        # Otherwise - process all malware file and create it
        if most_used_permissions_file_path:
            most_used_permissions_mat = np.genfromtxt(most_used_permissions_file_path, skip_header=True, dtype=str, delimiter=',')
        else:
            most_used_permissions_mat = self.extract_most_common_permissions_used(self._malicious_files_input_dir, TEMP_OUTPUT_FILENAME_MOST_COMMON_PERMISSIONS)

        # Sort that array from most used functions first. 
        most_used_permissions_mat = sorted(list(most_used_permissions_mat), reverse=True, key=lambda pair : int(pair[1]))

        # Extract most used api functions, of features_count size.
        self._most_used_permissions_array = np.array(most_used_permissions_mat)[0:self._features_count ,0]



    def extract_permissions_list(self, filepath):
        try:
            # Extact APK info using pyaxmlparser lib
            apk_info = APK(filepath)

            permissions_list = apk_info.get_declared_permissions() + apk_info.get_permissions()
            return permissions_list

        except Exception as ex:
            logging.getLogger().error(str(ex))
            return []



    def extract_most_common_permissions_used(self, in_directory_path, out_filepath):
        all_permissions_dict = {}

        for filepath in glob.iglob(f'{in_directory_path}/*'):

            # Extract persmissions list of each apk file and update the dictionary with each permission count accordingly 

            print('Processing: ' + filepath)
            permissions_list = self.extract_permissions_list(filepath)

            for permission_name in permissions_list:

                if not permission_name in all_permissions_dict:
                    all_permissions_dict[permission_name] = 1

                else:
                    all_permissions_dict[permission_name] = all_permissions_dict[permission_name] + 1


        # Now export that dictionary to csv file
        permissions_frequency_mat = [(perm, count) for perm, count in all_permissions_dict.items()]
        permissions_frequency_mat = np.array(permissions_frequency_mat)


        if out_filepath:
            CSV_FILE_HEADER = 'PERMISSION, COUNT'
            np.savetxt(out_filepath, permissions_frequency_mat , fmt='%s', delimiter=',', header=CSV_FILE_HEADER)

        return permissions_frequency_mat



    def get_feature_vector(self, file_path):

        if not os.path.isfile(file_path):
            raise FeaturesExtractionException("File not exsists!")

        permissions_list = self.extract_permissions_list(file_path)
        if not permissions_list:
            return None

        feature_vector = [1 if permission in permissions_list else 0 for permission in self._most_used_permissions_array]
        return np.array(feature_vector)


    def _create_partial_dataset(self, apk_files_input_dir):
       
        feature_vectors_list = []

        for filepath in glob.iglob(f'{apk_files_input_dir}/*'):

            print('Processing: ' + filepath)
            feature_vector = self.get_feature_vector(filepath)

            if feature_vector is None:
                continue

            feature_vectors_list.append(feature_vector)

        return np.array(feature_vectors_list)



    def create_dataset(self, output_dataset_file):

        benign_partial_dataset = self._create_partial_dataset(self._benign_files_input_dir)
        malicious_partial_dataset = self._create_partial_dataset( self._malicious_files_input_dir)

        # push to each matrix 1 coulumn of label 
        benign_dataset = np.column_stack((benign_partial_dataset, np.ones(benign_partial_dataset.shape[0]) * LABEL_BENIGN))
        malicious_dataset = np.column_stack((malicious_partial_dataset, np.ones(malicious_partial_dataset.shape[0]) * LABEL_MALICIOUS))

        final_dataset = np.concatenate((benign_dataset, malicious_dataset))
        np.savetxt(output_dataset_file, final_dataset , fmt='%s', delimiter=',')